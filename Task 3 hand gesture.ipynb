{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10TG0YPdXaL_rBba10Q-PC49AyZ6_SrLi","timestamp":1685266876557}],"authorship_tag":"ABX9TyN/S584ooLMFtoAEmHKaarN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import math\n","import scipy\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow.keras.layers as tfl\n","from tensorflow.python.framework import ops\n","!pip install opendatasets\n","import opendatasets as od\n","import pandas as pd\n","\n","od.download(\"https://www.kaggle.com/datasets/koryakinp/fingers\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AMX0KNlMsAA","executionInfo":{"status":"ok","timestamp":1685943906097,"user_tz":-330,"elapsed":17418,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}},"outputId":"aceee979-0105-4541-8a03-090302ce5d30"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n","Skipping, found downloaded files in \"./fingers\" (use force=True to force download)\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","# Path to the dataset directory\n","dataset_dir = '/content/fingers/train'\n","\n","# Initialize lists to store images and labels\n","images = []\n","labels = []\n","\n","# Iterate through each image file\n","for filename in os.listdir(dataset_dir):\n","    # Load the image using OpenCV\n","    image = cv2.imread(os.path.join(dataset_dir, filename), cv2.IMREAD_GRAYSCALE)\n","    \n","    # Resize the image to a desired size (e.g., 128x128)\n","    image = cv2.resize(image, (64, 64,))\n","    \n","    # Append the image to the images list\n","    images.append(image)\n","    \n","    # Get the label from the filename (the first character)\n","    label = int(filename[-6])\n","    \n","    # Append the label to the labels list\n","    labels.append(label)\n","\n","# Convert the lists to NumPy arrays\n","x_train = np.array(images)\n","y_train = np.array(labels)"],"metadata":{"id":"jiMlYWib9Mp1","executionInfo":{"status":"ok","timestamp":1685943975831,"user_tz":-330,"elapsed":16196,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","# Path to the dataset directory\n","dataset_dir = '/content/fingers/test'\n","\n","# Initialize lists to store images and labels\n","images = []\n","labels = []\n","\n","# Iterate through each image file\n","for filename in os.listdir(dataset_dir):\n","    # Load the image using OpenCV\n","    image = cv2.imread(os.path.join(dataset_dir, filename), cv2.IMREAD_GRAYSCALE)\n","    \n","    # Resize the image to a desired size (e.g., 128x128)\n","    image = cv2.resize(image, (64, 64,))\n","    \n","    # Append the image to the images list\n","    images.append(image)\n","    \n","    # Get the label from the filename (the first character)\n","    label = int(filename[-6])\n","    \n","    # Append the label to the labels list\n","    labels.append(label)\n","\n","# Convert the lists to NumPy arrays\n","x_test = np.array(images)\n","y_test = np.array(labels)"],"metadata":{"id":"PnBjGTiCF5KE","executionInfo":{"status":"ok","timestamp":1685944007229,"user_tz":-330,"elapsed":5219,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["\n","x_train = np.expand_dims(x_train, axis=-1)\n","x_test = np.expand_dims(x_test, axis=-1)"],"metadata":{"id":"EbHTm5FSMozP","executionInfo":{"status":"ok","timestamp":1685944016449,"user_tz":-330,"elapsed":706,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","\n","Y_train = to_categorical(y_train, num_classes=6)\n","\n","Y_test = to_categorical(y_test, num_classes=6)"],"metadata":{"id":"w4AM18ykNIhb","executionInfo":{"status":"ok","timestamp":1685944026014,"user_tz":-330,"elapsed":2,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["print (\"Y_train shape: \" + str(Y_train.shape))\n","print (\"Y_test shape: \" + str(Y_test.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAI0ZgBONbb_","executionInfo":{"status":"ok","timestamp":1685944057019,"user_tz":-330,"elapsed":385,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}},"outputId":"837ff942-8645-4092-906d-ebfe80d44d15"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["Y_train shape: (18000, 6)\n","Y_test shape: (3600, 6)\n"]}]},{"cell_type":"code","source":["def convolutional_model(input_shape):\n","\n","    input_img = tf.keras.Input(shape=input_shape)\n","    ## CONV2D: 8 filters 4x4, stride of 1, padding 'SAME'\n","    Z1 = tfl.Conv2D(filters= 8. , kernel_size=4 , padding='same',strides=1)(input_img)\n","    ## RELU\n","    A1 = tfl.ReLU()(Z1)\n","    ## MAXPOOL: window 8x8, stride 8, padding 'SAME'\n","    P1 = tfl.MaxPool2D(pool_size=8, strides=8, padding='SAME')(A1)\n","    ## CONV2D: 16 filters 2x2, stride 1, padding 'SAME'\n","    Z2 = tfl.Conv2D(filters= 16. , kernel_size=2 , padding='same',strides=1)(P1)\n","    ## RELU\n","    A2 =  tfl.ReLU()(Z2)\n","    ## MAXPOOL: window 4x4, stride 4, padding 'SAME'\n","    P2 = tfl.MaxPool2D(pool_size=4, strides=4, padding='SAME')(A2)\n","    ## FLATTEN\n","    F = tfl.Flatten()(P2)\n","    ## Dense layer\n","    ## 6 neurons in output layer. Hint: one of the arguments should be \"activation='softmax'\" \n","    outputs = tfl.Dense(units= 6 , activation='softmax')(F)\n","    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n","    return model"],"metadata":{"id":"OtQUMz8pNu-J","executionInfo":{"status":"ok","timestamp":1685944127832,"user_tz":-330,"elapsed":3,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["conv_model = convolutional_model((64, 64,1))\n","conv_model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","conv_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDymF69YNzSE","executionInfo":{"status":"ok","timestamp":1685944136085,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Tanmay Siddharth","userId":"03130811345977818681"}},"outputId":"345194f8-f51a-4b1a-9ec7-7aa67e3ac4e4"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 64, 64, 1)]       0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 64, 64, 8)         136       \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 64, 64, 8)         0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 8, 8, 8)          0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 16)          528       \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 8, 8, 16)          0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 2, 2, 16)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 1,054\n","Trainable params: 1,054\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"y_qKyo5cQYpy"}},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((x_train[0:1800,], Y_train[0:1800,]))\n","train_dataset = train_dataset.batch(64)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test[0:300,], Y_test[0:300,]))\n","test_dataset = test_dataset.batch(64)\n","history = conv_model.fit(train_dataset, epochs=100, validation_data=test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69nv7syXN5tZ","outputId":"c986d018-1144-4ab0-9702-2955d4a2a1b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","29/29 [==============================] - 5s 138ms/step - loss: 25.2947 - accuracy: 0.1661 - val_loss: 6.7976 - val_accuracy: 0.1333\n","Epoch 2/100\n","29/29 [==============================] - 6s 206ms/step - loss: 5.8131 - accuracy: 0.1522 - val_loss: 4.1090 - val_accuracy: 0.2400\n","Epoch 3/100\n","29/29 [==============================] - 3s 121ms/step - loss: 3.7387 - accuracy: 0.2556 - val_loss: 2.7470 - val_accuracy: 0.3700\n","Epoch 4/100\n","29/29 [==============================] - 5s 157ms/step - loss: 2.6125 - accuracy: 0.3644 - val_loss: 1.8927 - val_accuracy: 0.4400\n","Epoch 5/100\n","29/29 [==============================] - 3s 99ms/step - loss: 1.8635 - accuracy: 0.4739 - val_loss: 1.3695 - val_accuracy: 0.5533\n","Epoch 6/100\n","29/29 [==============================] - 3s 103ms/step - loss: 1.4443 - accuracy: 0.5672 - val_loss: 1.0673 - val_accuracy: 0.6333\n","Epoch 7/100\n","29/29 [==============================] - 4s 155ms/step - loss: 1.2011 - accuracy: 0.6211 - val_loss: 0.9065 - val_accuracy: 0.6867\n","Epoch 8/100\n","29/29 [==============================] - 5s 173ms/step - loss: 1.0368 - accuracy: 0.6628 - val_loss: 0.7782 - val_accuracy: 0.7267\n","Epoch 9/100\n","29/29 [==============================] - 4s 121ms/step - loss: 0.9046 - accuracy: 0.7067 - val_loss: 0.7041 - val_accuracy: 0.7600\n","Epoch 10/100\n","29/29 [==============================] - 5s 169ms/step - loss: 0.7939 - accuracy: 0.7356 - val_loss: 0.6359 - val_accuracy: 0.7733\n","Epoch 11/100\n","29/29 [==============================] - 3s 111ms/step - loss: 0.7028 - accuracy: 0.7589 - val_loss: 0.5839 - val_accuracy: 0.7900\n","Epoch 12/100\n","29/29 [==============================] - 3s 98ms/step - loss: 0.6291 - accuracy: 0.7856 - val_loss: 0.5253 - val_accuracy: 0.8133\n","Epoch 13/100\n","29/29 [==============================] - 3s 98ms/step - loss: 0.5646 - accuracy: 0.8017 - val_loss: 0.4674 - val_accuracy: 0.8300\n","Epoch 14/100\n"," 1/29 [>.............................] - ETA: 2s - loss: 0.6423 - accuracy: 0.8125"]}]},{"cell_type":"code","source":["import random\n","import cv2\n","from matplotlib import pyplot as plt\n","\n","numbers = list(range(1, 300))\n","random_array = random.sample(numbers, 10)\n","\n","fig = plt.figure(figsize=(10, 7))\n","\n","for i, idx in enumerate(random_array):\n","    img_resized = cv2.resize(x_test[idx], (64, 64))\n","    y_pred = np.argmax(conv_model.predict(np.expand_dims(x_test[idx], axis=0),verbose=0))\n","    ax = fig.add_subplot(1, 10, i+1)\n","    ax.imshow(img_resized, cmap='gray')\n","    ax.axis('off')\n","    ax.set_title(\"pred = \" + str(y_pred))\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"4kXXLPswN9i-"},"execution_count":null,"outputs":[]}]}